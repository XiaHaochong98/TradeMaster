{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "# 2. Data loading\n",
    "from data_loading import real_data_loading, sine_data_generation\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intervals(data):\n",
    "    index=data['index']\n",
    "    last_value=index[0]-1\n",
    "    last_index=0\n",
    "    intervals=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        if last_value!=index[i]-1:\n",
    "            intervals.append([last_index,i])\n",
    "            last_value=index[i]\n",
    "            last_index=i\n",
    "        last_value=index[i]\n",
    "    intervals.append([last_index, i])\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(data):\n",
    "    max_len=24\n",
    "    l=len(data)\n",
    "    to_fill=max_len-l\n",
    "    if to_fill!=0:\n",
    "        interval=max_len//to_fill\n",
    "        for j in range(to_fill):\n",
    "            idx=(interval+1)*j+interval\n",
    "            data.insert(min(idx,len(data)-1),float('nan'))\n",
    "    data=pd.Series(data).interpolate(method='polynomial', order=2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    norm_data = numerator / (denominator + 1e-7)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_normlization(data):\n",
    "    normalized_data=(data-data.min())/(data.max()-data.min()+ 1e-7)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_of_same_length(data,seq_len):\n",
    "    data_processed=[]\n",
    "    intervals=get_intervals(data)\n",
    "    temp_data=[]\n",
    "    data.drop(columns=['index'])\n",
    "    for interval in intervals:\n",
    "#         print(interval)\n",
    "        data_seg=data.iloc[interval[0]:interval[1],:]\n",
    "        for i in range(0, len(data_seg) - seq_len):\n",
    "            _x = data_seg.iloc[i:i + seq_len,:]\n",
    "            temp_data.append(_x)\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_prepareation(path):\n",
    "    data=pd.read_csv(path).reset_index()\n",
    "    tics=data['tic'].unique()\n",
    "    features=[ 'open', 'high', 'low', 'close', 'adjcp','zopen', 'zhigh', 'zlow', 'zadjcp', 'zclose', 'zd_5', 'zd_10',\n",
    "       'zd_15', 'zd_20', 'zd_25', 'zd_30', 'pct_return', 'adjcp_filtered',\n",
    "       'pct_return_filtered','volume']\n",
    "    ret=[]\n",
    "    for col in data.columns:\n",
    "        if col in features:\n",
    "            ret.append(col)\n",
    "    features=ret\n",
    "    for tic in tics:\n",
    "        data_by_tic=data.loc[data['tic']==tic,features].astype(float)\n",
    "        norm_data_by_tic=MinMaxScaler(data_by_tic)\n",
    "        data.loc[data['tic']==tic,features]=norm_data_by_tic\n",
    "    stock_group_num=len(data['stock_type'].unique())\n",
    "    regime_num=len(data['label'].unique())\n",
    "    for tic in tics:\n",
    "        for j in range(regime_num):\n",
    "            data_seg=data.loc[(data['tic']==tic) & (data['label']==j),['index','open','high','low','close','adjcp','volume']]\n",
    "    #         data_dict[(i,j)]=data_seg\n",
    "            data_seg.to_csv('./data/data_seg_'+tic+'_'+str(j)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data.\n",
    "\n",
    "- data_name: stock, energy, or sine\n",
    "- seq_len: sequence length of the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepareation(\"/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/DJI_all_labeled_3_24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prepareation('/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/GOOG_labeled_3_24.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_trainning(path):\n",
    "    data=pd.read_csv(path).drop('index', axis=1)\n",
    "    data=data.reset_index().rename(columns={data.index.name:'index'})\n",
    "#     display(data.head())\n",
    "    data=get_data_of_same_length(data,24)\n",
    "#     display(len(data))\n",
    "    data=[d.loc[:,['open','high','low','close','adjcp','volume']].to_numpy() for d in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOOG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOG_data={}\n",
    "for i in range(3):\n",
    "    GOOG_data['data_seg_GOOG_'+str(i)]=prepare_data_for_trainning('./data/data_seg_GOOG_'+str(i)+'.csv')\n",
    "    print(i,len(GOOG_data['data_seg_GOOG_'+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/DJI_all_labeled_3_24.csv\").reset_index()\n",
    "tics=data['tic'].unique()\n",
    "data_dict_tic={}\n",
    "for tic in tics:\n",
    "    data_dict_tic[tic]={}\n",
    "    for i in range(3):\n",
    "        data_dict_tic[tic]['data_seg_'+str(tic)+'_'+str(i)]=prepare_data_for_trainning('./data/data_seg_'+str(tic)+'_'+str(i)+'.csv')\n",
    "        print(tic,i,len(data_dict_tic[tic]['data_seg_'+str(tic)+'_'+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/DJI_all_labeled_3_24.csv\").reset_index()\n",
    "# display(data.columns)\n",
    "tic_group_pair=data.loc[:,['tic','stock_type']]\n",
    "tic_group_pair=tic_group_pair.groupby(['tic','stock_type']).size().reset_index(name='Freq')\n",
    "stock_group_num=len(data['stock_type'].unique())\n",
    "tic_in_group={}\n",
    "for group in range(stock_group_num):\n",
    "#     if group not in tic_in_groupï¼š\n",
    "#         tic_in_group[group]=[]\n",
    "    tic_in_group[group]=list(tic_group_pair.loc[tic_group_pair['stock_type']==group,:]['tic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tic_in_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/DJI_all_labeled_3_24.csv\").reset_index()\n",
    "stock_group_num=len(data['stock_type'].unique())\n",
    "data_dict_group={}\n",
    "for group in range(stock_group_num):\n",
    "    data_dict_group[group]={}\n",
    "    for i in range(3):\n",
    "        if 'data_seg_'+str(group)+'_'+str(i) not in data_dict_group[group]:\n",
    "            data_dict_group[group]['data_seg_'+str(group)+'_'+str(i)]=[]\n",
    "        for tic in tic_in_group[group]:\n",
    "            data_dict_group[group]['data_seg_'+str(group)+'_'+str(i)].extend(data_dict_tic[tic]['data_seg_'+str(tic)+'_'+str(i)])\n",
    "        print(group,i,len(data_dict_group[group]['data_seg_'+str(group)+'_'+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All dji stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/hcxia/TradeMaster_dev/TradeMaster/data/data/other/DJI_all_labeled_3_24.csv\").reset_index()\n",
    "tics=data['tic'].unique()\n",
    "data_all={}\n",
    "for i in range(3):\n",
    "    if 'data_seg_'+'all'+'_'+str(i) not in data_all:\n",
    "        data_all['data_seg_'+'all'+'_'+str(i)]=[]\n",
    "    for tic in tics:\n",
    "        data_all['data_seg_'+'all'+'_'+str(i)].extend(data_dict_tic[tic]['data_seg_'+str(tic)+'_'+str(i)])\n",
    "    print(i,len(data_all['data_seg_'+'all'+'_'+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data set:\n",
    "\n",
    "- GOOG_data\n",
    "- data_dict_tic (dict of dict by tic)\n",
    "- data_dict_group (dict of dict by group num)\n",
    "- data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GOOG_data.keys())\n",
    "print(data_dict_tic.keys())\n",
    "print(data_dict_group.keys())\n",
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train Static learning classification discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sktime.classification.kernel_based import RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_of_same_length_df(data,seq_len):\n",
    "    data_processed=[]\n",
    "    intervals=get_intervals(data)\n",
    "    temp_data=[]\n",
    "    data.drop(columns=['index'])\n",
    "    for interval in intervals:\n",
    "        data_seg=data.iloc[interval[0]:interval[1],:]\n",
    "        for i in range(0, len(data_seg) - seq_len):\n",
    "            _x = data[i:i + seq_len]\n",
    "            temp_data.append(_x)\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data_seg_'+\"0\"+'_'+\"0\"+'.csv')\n",
    "display(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tic in tics:\n",
    "    print(tic)\n",
    "    X=[]\n",
    "    y=np.empty(0)\n",
    "    for j in range(regime_num):\n",
    "        data=pd.read_csv('data_seg_'+tic+'_'+str(j)+'.csv').loc[:,['index', 'open', 'high', 'low', 'close', 'adjcp',\n",
    "       'pct_return', 'adjcp_filtered', 'pct_return_filtered']]\n",
    "        process_data=get_data_of_same_length_df(data,24)\n",
    "        label=np.full(len(process_data), j)\n",
    "        X.extend(process_data)\n",
    "        y=np.concatenate((y, label), axis=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    classifier = RocketClassifier(num_kernels=2000,n_jobs=-1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL single stock classification have unbelieve 100% acc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(stock_group_num):\n",
    "    print('stock_group',i)\n",
    "    X=[]\n",
    "    y=np.empty(0)\n",
    "    for j in range(regime_num):\n",
    "        data=pd.read_csv('data_seg_'+str(i)+'_'+str(j)+'.csv').loc[:,['index', 'open', 'high', 'low', 'close', 'adjcp',\n",
    "       'pct_return', 'adjcp_filtered', 'pct_return_filtered']]\n",
    "        process_data=get_data_of_same_length_df(data,24)\n",
    "        label=np.full(len(process_data), j)\n",
    "        X.extend(process_data)\n",
    "        y=np.concatenate((y, label), axis=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    classifier = RocketClassifier(num_kernels=2000,n_jobs=-1,use_multivariate='yes')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still 1.0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# classifier = TimeSeriesForestClassifier()\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train Deep learning classification discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Linux-5.15.0-58-generic-x86_64-with-debian-bullseye-sid\n",
      "python          : 3.7.15\n",
      "tsai            : 0.3.4\n",
      "fastai          : 2.7.10\n",
      "fastcore        : 1.5.27\n",
      "torch           : 1.13.1+cu117\n",
      "device          : 4 gpus (['NVIDIA RTX A6000', 'NVIDIA RTX A6000', 'NVIDIA RTX A6000', 'NVIDIA RTX A6000'])\n",
      "cpu cores       : 64\n",
      "threads per cpu : 2\n",
      "RAM             : 503.53 GB\n",
      "GPU memory      : [47.99, 47.99, 47.99, 47.99] GB\n"
     ]
    }
   ],
   "source": [
    "from tsai.all import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "my_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23008/3036702357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_all' is not defined"
     ]
    }
   ],
   "source": [
    "print(data_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=np.empty(0)\n",
    "for i in range(3):\n",
    "    data=data_all['data_seg_all_'+str(i)]\n",
    "    label=np.full(len(data), i)\n",
    "    X.extend([p.transpose() for p in data])\n",
    "    y=np.concatenate((y, label), axis=0)\n",
    "X=np.array(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X, y, splits = combine_split_data([X_train, X_test], [y_train, y_test])\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)\n",
    "dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)\n",
    "model = InceptionTime(dls.vars, dls.c)\n",
    "learn = Learner(dls, model, metrics=accuracy)\n",
    "learn.fit_one_cycle(25, lr_max=1e-3)\n",
    "learn.plot_metrics()\n",
    "learn.save_all(path='export', dls_fname='dls', model_fname='model', learner_fname='learner')\n",
    "#     display(type(X_train),X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner loaded:\n",
      "path          = 'export'\n",
      "dls_fname     = '['dls_0.pth', 'dls_1.pth']'\n",
      "model_fname   = 'model.pth'\n",
      "learner_fname = 'learner.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "learn=load_all(path='export', dls_fname='dls', model_fname='model',\n",
    "           learner_fname='learner', device=None, pickle_module=pickle, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=np.empty(0)\n",
    "for i in range(3):\n",
    "    data=data_all['data_seg_all_'+str(i)]\n",
    "    label=np.full(len(data), i)\n",
    "    X.extend([p.transpose() for p in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas, test_targets, test_preds=learn.get_X_preds(X_test, with_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_to_load=[\"data_dict_tic_APPL_generated\",\n",
    "               \"data_dict_group_3_generated\",\n",
    "              \"data_dict_group_4_generated\",\n",
    "               \"GOOG_data_generated\",\n",
    "              \"data_all_generated\"]\n",
    "load_data_dict={}\n",
    "for data in data_to_load:\n",
    "    with open( './generated_data/'+data+'.pickle', 'rb') as handle:\n",
    "        load_data_dict[data] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data_seg_GOOG_0', 'data_seg_GOOG_1', 'data_seg_GOOG_2'])\n"
     ]
    }
   ],
   "source": [
    "print(load_data_dict[\"GOOG_data_generated\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=np.empty(0)\n",
    "for i in range(3):\n",
    "    data=data_all['data_seg_all_'+str(i)]\n",
    "    label=np.full(len(data), i)\n",
    "    X.extend([p.transpose() for p in data])\n",
    "    y=np.concatenate((y, label), axis=0)\n",
    "X=np.array(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "X_test.extend([p.transpose() for p in load_data_dict[\"GOOG_data_generated\"][\"data_seg_GOOG_0\"]])\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_probas, test_targets, test_preds = learn.get_X_preds(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "def get_pre_res(pred_res,label):\n",
    "    res = json.loads(pred_res)\n",
    "    # print(res)\n",
    "    res=[int(r) for r in res]\n",
    "    # print(res)\n",
    "    c=Counter(res)\n",
    "    return c[label]/len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_score(data_dict):\n",
    "    res_dict = {}\n",
    "    for k, v in data_dict.items():\n",
    "        label = int(k[-1])\n",
    "        X_test = []\n",
    "        X_test.extend([p.transpose() for p in v])\n",
    "        X_test = np.array(X_test)\n",
    "        test_probas, test_targets, test_preds = learn.get_X_preds(X_test)\n",
    "        # print(k,label)\n",
    "        score = get_pre_res(test_preds, label)\n",
    "        res_dict[k] = score\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'data_seg_GOOG_0': 0.9881129271916791,\n",
       " 'data_seg_GOOG_1': 0.7913262099308611,\n",
       " 'data_seg_GOOG_2': 0.9849574885546108}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_style_score(load_data_dict[\"GOOG_data_generated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in load_data_dict.keys():\n",
    "    print(k,get_style_score(load_data_dict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_dict['data_dict_tic_APPL_generated'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_dict['data_dict_tic_APPL_generated']['data_seg_AAPL_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def calculate_slope(data,plot=False,num=3,name=''):\n",
    "    try:\n",
    "        number_of_sample=data.shape[0]\n",
    "    except: \n",
    "        number_of_sample=len(data)\n",
    "    sample_list=sample([i for i in range(number_of_sample)],num*num)\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(num,num)\n",
    "        for i, s in enumerate(sample_list):\n",
    "            data_s=data[s]\n",
    "            # print(data_s.shape)\n",
    "            data_s_adjcp=data_s[:,4].flatten()\n",
    "            ax[i//num][i%num].plot(data_s_adjcp)\n",
    "        plt.show()\n",
    "        fig.savefig('./fig/'+str(name)+'.png')\n",
    "    slope_list=[]\n",
    "    for i in range(number_of_sample):\n",
    "        data_s=data[i]\n",
    "        # print(data_s.shape)\n",
    "        data_s_adjcp=data_s[:,4].reshape(-1, 1)\n",
    "        if data_s_adjcp[0]==0:\n",
    "            continue\n",
    "        x=np.asarray([i for i in range(len(data_s_adjcp))]).reshape(-1, 1)\n",
    "        reg=LinearRegression().fit(x, data_s_adjcp)\n",
    "        slope=(100*reg.coef_/data_s_adjcp[0])[0][0]\n",
    "        # print(slope)\n",
    "        slope_list.append(slope)\n",
    "    print(pd.DataFrame(slope_list).describe())\n",
    "def get_slope_of_dict(data_dict,plot=False,num=3,prefix=''):\n",
    "    for k,v in data_dict.items():\n",
    "        regime=int(k[-1])\n",
    "        print(k)\n",
    "        calculate_slope(v,plot,num,prefix+str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOG_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slope_of_dict(data_all,True,3,'ori_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slope_of_dict(load_data_dict['data_all_generated'],True,3,'generated_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slope_of_dict(GOOG_data,True,3,'ori_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slope_of_dict(load_data_dict['GOOG_data_generated'],True,3,'generated_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slope_of_dict(load_data_dict['data_all_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key takeaway\n",
    "\n",
    "InceptionTime can do the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, splits = get_classification_data('LSST', split_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms  = [None, TSClassification()] # TSClassification == Categorize\n",
    "batch_tfms = TSStandardize()\n",
    "dls = get_ts_dls(X, new_y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])\n",
    "dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_list(data):\n",
    "    intervals=get_intervals(data)\n",
    "    std_list=[]\n",
    "    data.drop(columns=['index'])\n",
    "    for interval in intervals:\n",
    "        data_seg=data.iloc[interval[0]:interval[1],:].to_numpy()\n",
    "        std=data_seg.adj.std()\n",
    "        std_list.append(std)\n",
    "    return std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "mv_clf = TSClassifier(X, y, splits=splits, path='models', arch=InceptionTimePlus, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())\n",
    "mv_clf.fit_one_cycle(10, 1e-2)\n",
    "mv_clf.export(\"mv_clf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
